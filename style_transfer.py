# -*- coding: utf-8 -*-
"""style_transfer.ipynb

Automatically generated by Colaboratory.


"""
import torch
import torch.optim as optim
from torchvision import transforms, models

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

from format import image_format
from unnormalize import  un_normalize
from gram import gram_matrix
# torch.cuda.is_available()

vgg_model = models.vgg19(pretrained=True).features

for parameter in vgg_model.parameters():
  parameter.requires_grad_(False)

vgg_model.to(torch.device('cuda'))

content_image = image_format('content_image.jpg')
style_image = image_format('goku.jpg', image_shape=content_image.shape[-2:])

plt.imshow(un_normalize(style_image))

def feature_extract(image, model, layers=None):
  
  if layers is None:
    layers = {'0':'conv1_1','5':'conv2_1','10':'conv3_1','19':'conv4_1','21':'conv4_2','28':'conv5_1'}
  
  feature = {}
  x = image.to('cuda')
  
  for name, layer in model._modules.items():
    x = layer(x)
    if name in layers:
      feature[layers[name]] = x
  
  return feature

content_feature = feature_extract(content_image,vgg_model)
style_feature = feature_extract(style_image,vgg_model)
gram_style = {layer:gram_matrix(style_feature[layer]) for layer in style_feature}
target = content_image.clone().requires_grad_(True).to('cpu')

style_weights = {'conv1_1':1, 'conv2_1':0.75, 'conv3_1':0.2, 'conv4_1':0.2,'conv5_1':0.1}
alpha = 1
beta = 1e6

# content_feature

optimizer = optim.Adam([target], lr=0.003)
show_every = 1000
steps = 1000

for ind in range(1, steps+1):
  target_features = feature_extract(target, vgg_model)
  content_loss = torch.mean((target_features['conv4_2'] - content_feature['conv4_2']) **2)
  style_loss = 0
  
  for layer in style_weights:
    target_feature = target_features[layer]
    abc,depth,height,weight = target_feature.shape
    target_gram = gram_matrix(target_feature)
    style_gram = gram_style[layer]
    layer_style_loss = style_weights[layer] * torch.mean((target_gram - style_gram) **2)
    style_loss += layer_style_loss / (depth*height*weight)
  
  total_loss = alpha*content_loss + beta*style_loss
  optimizer.zero_grad()
  total_loss.backward()
  optimizer.step()
  
  if ind % show_every == 0:
    plt.imshow(un_normalize(target))
    plt.show()

fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))
ax1.imshow(un_normalize(content_image))
ax2.imshow(un_normalize(style_image))
ax3.imshow(un_normalize(target))